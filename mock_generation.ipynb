{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "## Requirements\n",
    "\n",
    "* pyspark 2.3\n",
    "* pandas\n",
    "* numpy\n",
    "* jupyter\n",
    "\n",
    "## Hadoop\n",
    "\n",
    "<img src=\"images/hadoop.jpg\">\n",
    "\n",
    "* Open source distributed processing and storage platform\n",
    "* Layered architecture\n",
    "* Fault tolerant\n",
    "\n",
    "## HDFS\n",
    "\n",
    "<img src=\"images/hdfs.jpg\">\n",
    "\n",
    "* Replication\n",
    "* Tiered storage\n",
    "* Rack awareness\n",
    "\n",
    "## YARN\n",
    "\n",
    "<img src=\"images/yarn.png\">\n",
    "\n",
    "* Queues, priority, fair sharing\n",
    "* Accounting\n",
    "\n",
    "## Spark\n",
    "\n",
    "<img src=\"images/spark.png\">\n",
    "\n",
    "* RDD\n",
    "* DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's create a mock!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession, Row\n",
    "\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://ll-tallada.pic.es:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.3.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>PySparkShell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<SparkContext master=local[*] appName=PySparkShell>"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Halo catalog"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From CosmoHub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Original query\n",
    "halo_sql = \"\"\"\n",
    "    SELECT id AS halo_id, num_p AS halo_num_p,\n",
    "        x AS halo_x, y AS halo_y, z AS halo_z,\n",
    "        vx AS halo_vx, vy AS halo_vy, vz AS halo_vz\n",
    "    FROM cosmohub.my_halos\n",
    "    WHERE pid=-1 AND octant=1\n",
    "        AND PMOD((180.0/PI() * ATAN2(y,x)) + 360., 360.) BETWEEN 0 AND 3\n",
    "        AND 90 - (180.0/PI() * ATAN2(SQRT(x*x+y*y),z)) BETWEEN 0 AND 3\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3x3 patch\n",
    "halo_sql = \"\"\"\n",
    "    SELECT id AS halo_id, num_p AS halo_num_p,\n",
    "         x AS halo_x,   y AS halo_y,   z AS halo_z,\n",
    "        vx AS halo_vx, vy AS halo_vy, vz AS halo_vz,\n",
    "        SQRT(x*x + y*y + z*z) AS halo_r\n",
    "    FROM handson.halos_3x3\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.sql(halo_sql).limit(5).cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From local file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.csv(\n",
    "    'file:////home/tallada/Projectes/git/lsst_hadoop_handson/halo_sample.csv.bz2',\n",
    "    comment='#',\n",
    "    header=True,\n",
    "    inferSchema=True,\n",
    ").limit(5).cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[halo_id: bigint, halo_num_p: int, halo_x: double, halo_y: double, halo_z: double, halo_vx: double, halo_vy: double, halo_vz: double]"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------+-------+-------+-------+--------+--------+--------+\n",
      "|halo_id|halo_num_p| halo_x| halo_y| halo_z| halo_vx| halo_vy| halo_vz|\n",
      "+-------+----------+-------+-------+-------+--------+--------+--------+\n",
      "|3839342|        44|447.352|2.12842|0.88135| 1324.26|-2761.71|-2170.23|\n",
      "|3844782|       433|571.893|9.55396|9.76489| -667.56|  756.82| -605.93|\n",
      "|3848430|        23|317.961|3.21973|5.12695|-1024.17|   248.3| -160.01|\n",
      "|3856622|        56|444.658|2.62061|0.99072| 2246.39|-1378.16|-1777.96|\n",
      "|3862350|      1554|509.772| 2.0625|6.91553| -744.19|  -458.2|   38.89|\n",
      "+-------+----------+-------+-------+-------+--------+--------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Halo mass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "particle_mass = 2.398e9\n",
    "\n",
    "def halo_lm(num_p):\n",
    "    return f.log10(particle_mass * num_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.withColumn('halo_lm', halo_lm(df['halo_num_p']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[halo_id: bigint, halo_num_p: int, halo_x: double, halo_y: double, halo_z: double, halo_vx: double, halo_vy: double, halo_vz: double, halo_lm: double]"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------+-------+-------+-------+--------+--------+--------+------------------+\n",
      "|halo_id|halo_num_p| halo_x| halo_y| halo_z| halo_vx| halo_vy| halo_vz|           halo_lm|\n",
      "+-------+----------+-------+-------+-------+--------+--------+--------+------------------+\n",
      "|3839342|        44|447.352|2.12842|0.88135| 1324.26|-2761.71|-2170.23|11.023301855249017|\n",
      "|3844782|       433|571.893|9.55396|9.76489| -667.56|  756.82| -605.93|12.016337075116196|\n",
      "|3848430|        23|317.961|3.21973|5.12695|-1024.17|   248.3| -160.01|10.741577014780423|\n",
      "|3856622|        56|444.658|2.62061|0.99072| 2246.39|-1378.16|-1777.96|11.128037205769031|\n",
      "|3862350|      1554|509.772| 2.0625|6.91553| -744.19|  -458.2|   38.89|12.571300193227726|\n",
      "+-------+----------+-------+-------+-------+--------+--------+--------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Halo R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "def halo_r(x, y, z):\n",
    "    return f.sqrt(x*x + y*y + z*z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.withColumn('halo_r', halo_r(df['halo_x'], df['halo_y'], df['halo_z']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------+-------+-------+-------+--------+--------+--------+------------------+------------------+\n",
      "|halo_id|halo_num_p| halo_x| halo_y| halo_z| halo_vx| halo_vy| halo_vz|           halo_lm|            halo_r|\n",
      "+-------+----------+-------+-------+-------+--------+--------+--------+------------------+------------------+\n",
      "|3839342|        44|447.352|2.12842|0.88135| 1324.26|-2761.71|-2170.23|11.023301855249017| 447.3579314749196|\n",
      "|3844782|       433|571.893|9.55396|9.76489| -667.56|  756.82| -605.93|12.016337075116196| 572.0561464379119|\n",
      "|3848430|        23|317.961|3.21973|5.12695|-1024.17|   248.3| -160.01|10.741577014780423| 318.0186312129769|\n",
      "|3856622|        56|444.658|2.62061|0.99072| 2246.39|-1378.16|-1777.96|11.128037205769031|444.66682593475593|\n",
      "|3862350|      1554|509.772| 2.0625|6.91553| -744.19|  -458.2|   38.89|12.571300193227726|509.82307759205145|\n",
      "+-------+----------+-------+-------+-------+--------+--------+--------+------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Halo True Redshift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "import astropy.units as u\n",
    "\n",
    "from astropy.cosmology import LambdaCDM, z_at_value\n",
    "\n",
    "from pyspark.sql import types as t\n",
    "from pyspark.sql.functions import pandas_udf, PandasUDFType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "cosmology = LambdaCDM(H0=100, Om0=0.319, Ode0=1-0.319, Ob0=0.049)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "def halo_true_redshift(halo_r):\n",
    "    return z_at_value(\n",
    "        cosmology.comoving_distance,\n",
    "        halo_r * u.Mpc\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.13808325920114975"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "halo_true_redshift(400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-224-0d3238768b4a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m halo_true_redshift(\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m400\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m600\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m )\n",
      "\u001b[0;32m<ipython-input-222-2d24fd11b8bb>\u001b[0m in \u001b[0;36mhalo_true_redshift\u001b[0;34m(halo_r)\u001b[0m\n\u001b[1;32m      2\u001b[0m     return z_at_value(\n\u001b[1;32m      3\u001b[0m         \u001b[0mcosmology\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomoving_distance\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m         \u001b[0mhalo_r\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMpc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     )\n",
      "\u001b[0;32m/home/tallada/Projectes/env/spark23/local/lib/python2.7/site-packages/astropy/cosmology/funcs.pyc\u001b[0m in \u001b[0;36mz_at_value\u001b[0;34m(func, fval, zmin, zmax, ztol, maxfun)\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0mfval_zmin\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzmin\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m     \u001b[0mfval_zmax\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzmax\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msign\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfval\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mfval_zmin\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msign\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfval_zmax\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mfval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m         warnings.warn(\"\"\"\\\n\u001b[1;32m    122\u001b[0m \u001b[0mfval\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mbracketed\u001b[0m \u001b[0mby\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzmin\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzmax\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mThis\u001b[0m \u001b[0mmeans\u001b[0m \u001b[0meither\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()"
     ]
    }
   ],
   "source": [
    "halo_true_redshift(\n",
    "    np.array([400, 500, 600])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "halo_z_min = 0\n",
    "halo_z_max = 2.5\n",
    "halo_z_n_bins = 1000\n",
    "\n",
    "halo_z_bins = np.linspace(halo_z_min, halo_z_max, halo_z_n_bins)\n",
    "halo_r_bins = cosmology.comoving_distance(halo_z_bins).value\n",
    "\n",
    "def r_to_z(halo_r):\n",
    "    return np.interp(halo_r, halo_r_bins, halo_z_bins, halo_z_min, halo_z_max)\n",
    "\n",
    "@pandas_udf('double', PandasUDFType.SCALAR)\n",
    "def halo_true_redshift(halo_r):\n",
    "    idx = halo_r.index\n",
    "    values = r_to_z(halo_r)\n",
    "    return pd.Series(values, index=idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.13808350695226523"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_to_z(400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.13808351, 0.17422571, 0.21110203])"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_to_z(np.array([400, 500, 600]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.withColumn('halo_true_redshift', halo_true_redshift(df['halo_r']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[halo_id: bigint, halo_num_p: int, halo_x: double, halo_y: double, halo_z: double, halo_vx: double, halo_vy: double, halo_vz: double, halo_lm: double, halo_r: double, halo_true_redshift: double]"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------+-------+-------+-------+--------+--------+--------+------------------+------------------+-------------------+\n",
      "|halo_id|halo_num_p| halo_x| halo_y| halo_z| halo_vx| halo_vy| halo_vz|           halo_lm|            halo_r| halo_true_redshift|\n",
      "+-------+----------+-------+-------+-------+--------+--------+--------+------------------+------------------+-------------------+\n",
      "|3839342|        44|447.352|2.12842|0.88135| 1324.26|-2761.71|-2170.23|11.023301855249017| 447.3579314749196|0.15511076199346596|\n",
      "|3844782|       433|571.893|9.55396|9.76489| -667.56|  756.82| -605.93|12.016337075116196| 572.0561464379119|0.20072066339424757|\n",
      "|3848430|        23|317.961|3.21973|5.12695|-1024.17|   248.3| -160.01|10.741577014780423| 318.0186312129769| 0.1089703868010368|\n",
      "|3856622|        56|444.658|2.62061|0.99072| 2246.39|-1378.16|-1777.96|11.128037205769031|444.66682593475593| 0.1541393350525811|\n",
      "|3862350|      1554|509.772| 2.0625|6.91553| -744.19|  -458.2|   38.89|12.571300193227726|509.82307759205145|0.17781452072700768|\n",
      "+-------+----------+-------+-------+-------+--------+--------+--------+------------------+------------------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
